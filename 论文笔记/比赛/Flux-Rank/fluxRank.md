## 挑战

### 问题

1. 如何快速检测KPI的异常开始时间
2. 如何分类KPIs，因为一个失误会导致很多KPI异常，我们要将这种有异常关联的点拿到（一个服务故障常常与许多机器KPI异常在时间上重合，可以使用时间做特征向量）。
3. 如何排序：对于大型软件服务，经常会出现机器级的并发但不相关的异常。这意味着，对于服务失败，第2阶段以上可能会输出多个集群结果。因此，在阶段3中，我们必须对阶段2的聚类结果进行排序，以便与故障最相关的聚类结果出现在顶部。

### 贡献

1. 我们提出了一种基于核密度估计的非参数轻量级算法，用于量化和比较特定时间内大量不同kpi的变化，解决了挑战1。
2. 为了解决挑战2，我们提出了变更的矢量表示、距离函数和基于dbscan的集群算法，该算法将kpi组织为摘要，以表示模块的异常模式。
3. 为了解决挑战3，我们提出了一个有限元向量和一个基于逻辑回归的排序算法，它可以将根本原因摘要(RCD)排在最前面。


FluxRank平均减少了80%以上的定位时间。

## Change quantification

如前所述，在变化量化阶段，我们试图量化机器kpi的变化，这些kpi是通过`change degrees`来度量的。

变化程度可用于比较不同类型的kpi(例如，CPU利用率、内存利用率、I/O率)。此外，当服务发生故障时，根本原因机器的KPI将首先更改，然后是受此故障影响的机器的KPI更改。引入 Tc`change start time`

显然，更改量化的设计目标是快速准确地确定更改开始时间，并确定大量不同kpi的服务故障前后的更改程度。

回想一下，传统的异常检测算法如[20-23]无法实现上述目标，因为它们需要对大量不同的kpi进行算法选择和参数调优。因此，我们建议在变更量化中使用两步设计:(1)应用梯度来识别Tc;(2)使用核密度估计(KDE)来确定变更程度。

### Change Start Time

寻找KPI的变更开始时间(Tc)可以转换为一个经典的变更点检测问题。

kpi太多且缺乏标签，因此，监督学习方法不能使用，因为没有变标签。此外，该算法应该快速识别Tc以进行缓解，因此上述计算效率低下的无监督学习方法也不能应用于我们的场景。

正如前面提到的，与一般的变更点检测问题不同，在我们的场景中，**服务故障时间是给定的，我们只需要开发一个算法来检测故障时间周围的KPI更改**。如图1所示，可以根据服务KPI确定故障启动时间Tf，缓解启动时间Tm是操作员确认故障并开始缓解的时间。

由于故障传播的延迟，**根本原因机器的kpi可以在Tf之前更改。为了确定kpi的变化开始时间，我们设置了一个回溯窗口[Tf−w1, Tm]**，其中w1是Tf之前的时间长度。实际上，w1是一个可配置的参数。一方面，如果w1设置得太大，FluxRank可能会错误地包含一些与服务失败无关的KPI更改。如果w1设置得太小，FluxRank可能会错过一些根本原因机器的KPI更改。

图3

在分析82年年代失败在一年内,我们得到变化之间的延迟启动时间机器根源的kpi和失败的开始时间如图3所示,并发现80%的延迟是不到9分钟,最大延迟是19分钟。因此，我们在评估时根据经验将w1设置为30分钟。

在实践中，后视窗口中的KPI数据点的数量可以很少，因为监视间隔可以是每分钟(在我们的场景中是50%的情况)，并且少量的数据点不能支持复杂的变更点检测算法。因此，我们将重点放在只涉及简单计算的算法上。在这项工作中，我们设计了一个简单而有效的变更点检测算法，该算法利用KPI数据的绝对导数来自动、准确和有效地识别变更开始时间。Abs_Dev计算v的绝对梯度。

### Change Degree

如§I所述，FluxRank的第一个挑战是设计一个非参数的轻量级算法来量化和比较大量不同kpi的变化。**因此，我们建议使用变化的观察概率来表示变化的程度，因为概率是自然聚集的定量，可以在不同类型的kpi之间进行比较。**我们无法找到其他指标来表示和量化KPI更改，这些更改可以满足上述需求。

${x_i}$为$[T_c-w_2, T_c)$段的数据，${x_j}$为$[T_c,T_m]$段的数据 ${x_i}$是变化前平稳的数据、 ${x_j}$ 是变化后的数据。构造一个$P(\{x_j\}|\{x_i\})$。这个概率表示变化的程度:概率越小，变化的程度越大。

为了简化计算${x_j}$是iid的。假设{xi}是由一个随机变量X生成的，那么X的概率分布可以用{xi}来估计。

$$P_o(\{x_j\}|\{x_i\}) = \prod_{j=1}^l P(X\geqx_j|\{x_i\})$$

$$P_u(\{x_j\}|\{x_i\}) = \prod_{j=1}^l P(X\leq x_j|\{x_i\})$$

${x_j}$中样本的数量不仅取决于$(T_m−T_c]$的长度，还取决于KPI数据的收集间隔。如果两个kpi具有不同的收集间隔，$P_o(\{x_j\}|\{x_i\})$和$P_u(\{x_j\}|\{x_i\})$将非常不同，因为$P_o(\{x_j\}|\{x_i\})$和$P_u(\{x_j\}|\{x_i\})$都取决于{xj}中数据点的数量。为了比较不同收集区间的KPI变化，我们直接使用几何平均值，将负值转换为正值。因此，向上变化的o值和向下变化的u值将是


然后，剩下的问题是如何估计给定的X {xi}的概率分布。通常的解决方法是假设X服从高斯分布，然后通过样本均值和样本方差来估计概率分布。但很多不服从高斯，因此使用KDE。

更好的估计分布需要w2大一些。因此，过大的w2会导致模型不准确，我们根据经验将w2设为1h。

估计出的各种分布：

CPU_IDLE之类的服从Beta分布，可以使用截距取估计相应的分布。
SYS_OOM泊松分布(where λ is the expected number of events per interval, which can be set to xi)

高斯分布:默认的核函数KDE。若以上两种分布不能对kpi进行建模，则采用高斯分布对kpi进行建模。高斯核函数的细节可以在中找到。

## Digest Distillation

对于部署在多个数据中心的大型软件服务，它通常由10个∼100个模块组成，有数万个kpi。虽然变更量化算法可以滤除大量的正常kpi，但仍有大量的异常kpi存在。在我们的实验(§VI)中，异常kpi的数量为10,653。手动逐个筛选这些kpi对操作人员来说仍然是一项艰巨的工作。为了快速定位故障机器，这些kpi应该以清晰的方式组织。我们建议将kpi集中到摘要中，这是操作人员易于理解的方法。

Digest Distillation的基本思想是将具有类似KPI更改模式的机器聚集在一起。输入是§II中所有量化的KPI更改。首先，每台机器的kpi的变化度(o和u)可以形成一个向量$(O_0,u_0,....)$来表示机器的变化模式。

### distance

距离函数计算两个向量之间的相似度。我们的直觉是将kpi一起变化的机器分组到一个集群中。欧式距离是一个被广泛采用的距离函数，但它不能很好地捕捉“两个kpi改变其他指标”。欧几里得距离度量两个向量的绝对距离。当两个kpi同时变化时，不同变化程度下的欧式距离可能很大，但相关性很强。因此，我们采用相关作为距离函数

+ Pearson Correlation (beast)
+ Kendall's tau
+ Spearman Correlation

后两个基于排序值的差异很小，会使排名变化很大。

这三种方法的结果r为[−1,1]中的一个值，其中1表示完全正相关，0表示不相关，-1表示完全负相关。我们使用以下公式将相关系数r转换成距离:距离= 1−r。

### cluster algorithm

+ K-means 
+ Gaussian mixture
+ hierarchical clustering
+ DBSCAN

K-means、Gaussian mixture 需要集群的数量作为输入，这在我们的场景中是不可用的。
hierarchical clustering不需要簇号，但需要两个子簇的距离函数。推导两个簇之间的相关距离并不容易。

DBSCAN只依赖于距离函数，不需要输入簇号。它有两个参数:eps和minPts。eps指定一个邻域的半径，该半径控制两个项目在邻域图中是否有一条边。minPts(minPts≥2)指定核心点距离eps内的最小点。我们可以通过领域知识来确定minPts(minPts ≥ 2) specifies，并使用k-dist法来确定eps。然而，minPts在实践中很难确定。

附加约束:理论上，来自不同模块的机器可以聚集在一起。其中一些集群可以直观地解释，比如数据中心级别的网络中断，但是大多数集群无法直观地解释。因此，我们采用了一种保守的方法，**即只对来自相同模块的机器进行集群**。

## Rank

如图2所示，最后一个阶段是根据阶段2(§III)对digest的output进行排序。需要对经过Digest Distillation进行排序，以便快速定位根本原因所在的机器。我们提出了一个排序算法来对digest进行排序，这样与根本原因最相关的摘要就可以列在顶部。**在这里，我们采用学习-排序的点态方法来训练一个分类器使用逻辑回归**。学习排序是机器学习在构建排序模型中的应用。接下来，我们将介绍用于训练学习排名模型的特性。

经过聚类的几个效应：

1. 根因机器的某些kpi的更改开始时间早于Tf，这意味着这些kpi在故障开始时间之前就已经更改了。这是合理的，因为根本原因机器的故障需要一些时间来影响服务的关键KPI。
2. 开始时间变化的kpi根源机器彼此相似,而改变其他机器的kpi的开始时间可能不是类似,因为它需要时间从根源机器故障传播到其他机器和模块和花费的时间可能会受到一些随机因素的影响。
3. 一些根本原因的kpi具有很大的变化程度。
4. 根因机器数量的比例与根因有关，因为更多的根本原因机器有更大的影响。

接下来，我们将根据上面的观察为每个digest建立特征。让我们先介绍这些符号。d表示摘要，I表示机器。我们使用上标来表示KPI，使用下标来表示机器。例如,好的I表示机器I上KPI k向上变化的程度。

### Choosing Candidate KPI Set

通过效应1，我们首先选择在故障启动时间Tf之前发生变化的KPI作为候选KPI集，表示为`candidate_set`更具体地说，digest d的所有特性都是由它的候选集`candidate set`构造的。
。$T_{C\{I\}}^k$表示KPI的变化开始时间集合，$\hat{T}_{C\{I\}}^k$为$T_c^{k}$是平均值。

### Feature Extraction

首先,特征提取的变化开始时间kpi在候选集`candidate_set`，出于效应1,我们使用最大值,最小值,求和,意思代表的分布$\hat{T}_c^{k}$的kpi的候选集,用最大Tc, 最小Tc, 加和Tc，平均Tc。

## System Implementation

由于kpi是失败本地化的基本输入，所以kpi应该以某种方式反映失败的根本原因。为了使我们的实验更一般化，更容易理解，这里我们使用Linux系统的标准机器KPI作为KPI集。表一显示了47个Linux系统的标准机器KPI用于评估，包括CPU、内存、磁盘、网络和操作系统内核的状态。可以从Linux系统的/proc目录中的特殊文件中收集kpi的值