## Quantization Aware Training

量化感知训练在量化后还继续训练（微调）。可以使用从头开始训练和使用pre-train模型进行训练。一般使用pre-train模型进行进一步量化，多篇文献反映pre-train模型微调比从头训练的结果要好很多。

**有什么优点**

1. 量化感知训练比训练后的量化方案效果要好很多，在8bit量化级别基本可以逼近全精度，4bit上也会让结果显著的提高。
2. 训练消除了symmetric和asymmetric的差距。

### 量化感知训练的问题

1. 梯度如何计算。
2. BN操作应该如何做。（之后讨论）

#### 梯度计算的痛点

量化函数的形状如下，如果反向传播的时计算梯度，梯度就一直会为0，而造成无法训练的问题

![](https://i.loli.net/2019/10/31/KWMtgQR6BVGuFj5.png)

传统的解决方案。

在论文*Binaryconnect: Training deep neural networks with binary weights during propagations* 中提出`straight through estimator`方案，简称`STE`，之中方案在量化反向传播时，使用另一个函数（如下）代替原有的量化函数。
$$x_{o u t}=\operatorname{clamp}\left(x_{\min }, x_{\max }, x\right)$$
因此方向传播时公式就变成：

$$\begin{aligned} w_{f l o a t} &=w_{f l o a t}-\eta \frac{\partial L}{\partial w_{o u t}} \cdot I_{w_{o u t} \in\left(w_{m i n}, w_{m a x}\right)} \\ w_{o u t} &=\operatorname{Sim} Q u a n t\left(w_{f l o a t}\right) \end{aligned}$$

图像如下:

![](https://i.loli.net/2019/10/31/jk6JGToB52Iu9ld.png)

但是这又会导致另外一个问题，正向和反向近似会导致梯度失配问题，这使得训练过程很不稳定。

这也引出了之后的解决办法。

### 解决梯度的问题

#### 使用另一个系列近似的函数去代替量化函数

*Quantization Network(CVPR2019)* 和 *Differentiable Soft Quantization: Bridging Full-Precision and Low-Bit Neural Networks(ICCV2019)*都是基于这个思路。

两个文章前者使用`sigmoid`函数去近似，后者使用`tanh`去近似。但思路上略有不同

前者

![](https://i.loli.net/2019/10/31/EKti9M1yqleJGDP.png)

后者

![](https://i.loli.net/2019/10/31/m38eLYTdK2sNGMp.png)

两者都使用一个参数在训练中调整近似函数对量化函数的近似程度。

前者将每一段的sigmoid函数改变成为$sigmoid(x) = \frac{1}{1 + exp(-Tx)}$ 当`T`越大时候sigmoid就越接近标准的量化函数。

![](https://i.loli.net/2019/10/31/F3MsgxhLPzGCOpD.png)

然后在训练的时候，使用逐渐递减的策略进行调整。

![](https://i.loli.net/2019/10/31/3zylMqtvRAd2bJP.png)

使用参数$\alpha$进行权衡。相对来说使用$\alpha$权衡。

两者在参数训练时的选择，前者使用传统的随着`epoch`不断变化而逐步提上`k`从而使用的在训练中近似函数不断的逼近标准量化函数。它的问题是不同的网络可能量化收敛时有差异，很难确定K随着`epoch`的衰减程度。

而后者使用了进化策略进行操作$\alpha$将$\alpha$设置成可训练的参数，使用L2正则化去约束参数$\alpha$（更好的收敛）。

优点：不同控制不同网络的衰减速度，只需要指定初始值，在训练中不断的变化，由训练过程与约束控制。（该文章并未讨论初始值对整个效果的影响）。提高网络训练中的自动能力。

缺点是： 收敛的速度较慢（前期参数很不稳定，有较大的起伏，该文章并没有给出原因和具体的分析）。

