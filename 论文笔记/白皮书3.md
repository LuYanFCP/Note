## 最佳实践(training best practices)

### 随机量化 VS 确定量化

确定量化的效果更好

![](https://i.loli.net/2019/10/26/JEmT4WHYuBPMjbV.png)

### 使用预训练模型量化后再微调 VS 从头开始训练

预训练模型量化后再微调效果比较好
![](https://i.loli.net/2019/10/26/XhjZD6Rrdm25LJn.png)

### BN的最佳实践
correction and freeze BN的效果是最好的
![](https://i.loli.net/2019/10/26/xTDS1ryIJtl6uPY.png)

### 是否使用滑动平均

在量化时慎用滑动平均。即使是在瞬时和滑动平均浮点权值的微小变化也会导致量化的权值有显著的不同，损害性能。EMA长期会导致性能损失

![](https://i.loli.net/2019/10/26/UViWbLxZSJDr1wo.png)

## 模型结构的建议

+ 不要给激活值设定边界（不要使用ReLU6之类的）
+ 权衡width和quantization：过参数化的模型(over-parameterized model)更容易量化。即使对于像mobilenet这样的精简架构，也可以用权重的精度来权衡depth multipliers。

## run-time

量化之后我们使用 Android 的NN-API在与float相比，我们看到量化推断的速度提高了2倍到3倍，而高通dsp的速度提高了近10倍。

## 建议

+ 算子融合：在一个循环中执行尽可能多的操作可以降低内存访问的成本，并在运行时和功耗方面提供显著的改进。
+ 压缩内存访问:可以通过动态地支持权值的解压缩(和激活)来优化内存带宽。一种简单实现方式是支持低比特的模型存储。
+ 虽然4位和8位精度足以进行分类，但对于回归应用程序(如超分辨率和HDR图像处理)可能需要更高的精度支持。
+ 每层位宽的选择:我们期望网络的许多层可以以较低的精度处理。具有这种灵活性可以进一步减少模型大小和处理时间。
+ 支持pre-channel量化。

## 总结与未来的工作

### 量化模型

1. 使用 symmetric-pre-channel量化和post-training 量化作为模型量化的开始，如果缺少精度可以使用fine-tune去改善表现。
2. 量化感知训练可以缩小到浮点精度的差距，在我们的实验中，甚至当所有层都被量化到4位精度时，也可以将这个差距缩小到8位量化权值的5%以内。

### 表现

1. 8bit量化后推理可以在CPU上提供2倍到3倍的加速，在提供专门的低比特运算优化上，可以提供接近10倍的加速高通DSP与HVX。
2. 通过均匀量子化，可以在不损失精度的情况下使模型尺寸减小4倍。使用非均匀量化技术如K-means可以获得更高的压缩。

### 训练技术

1. 量化感知训练通过在训练过程中对量化的权重和激活进行建模，可以大幅度提高模型的准确性。
2. 为了提高量化模型的准确性，需要对批量标准化进行特殊处理。
3. 量化推理与训练前向匹配是关键。
4. 训练过程中的随机量化比确定性量化效果差。
5. 在量化感知训练中，加权的指数移动平均可能低于瞬时估计，必须谨慎使用。

### 量化的模型架构

1. 过参数的模型对压缩损失不敏感。
2. 在单一架构中，可以权衡特性映射和量化，更多的特性映射允许更低的位宽内核。
3. 通过在训练中不限制激活的范围，然后将其量化，而不是将范围限制在一个固定的值，可以获得更高的准确性。在我们的实验中，使用ReLU比使用ReLU6更好。

### 发展

1. 为了更好地控制权重和激活的动态范围，正则化技术可以提供进一步的改进。
2. 模型蒸馏训练会提高模型的准确度。
3. 强化学习会应用在pre-layer量化的权重和激活，以提供进一步的压缩和性能增益的硬件加速器。
